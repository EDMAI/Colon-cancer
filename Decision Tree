###################################################
# 의사결정트리(Decision Tree)
###################################################
# - 종속변수(y변수) 존재
# - 종속변수 : 예측에 Focus을 두는 변수
# - 비모수 검정 : 선형성, 정규성, 등분산성 가정 필요없음
# - 단점 : 유의수준 판단 기준 없음(추론 기능 없음)
# - 규칙(Rule)을 기반으로 의사결정트리 생성


###########################################
# party 패키지를 적용한 분류분석
###########################################

# part패키지 설치
install.packages("party")
library(party) # ctree() 제공

#----------------<<실습1>>-------------------------------
# R에서 기본으로 제공되는 airquality 데이터 셋을 이용하기 위해서 
#  - Temp(온도)에 영향을 미치는 변수를 알아보기 -  
# airquality 데이터 셋 153개의 관측치와 6개의 변수로 구성되어 있으며
# New York의 대기에 관한 질을 측정한 데이터 셋이다. 
# 주요 변수로는 Ozone(오존수치), Solar.R(태양광), Wind(바람), 
# Temp(온도), Month(측정 월), Day(측정 날짜) 등이 있다.
#--------------------------------------------------------

# airquality 데이터 셋 로딩
library(datasets)
str(airquality)

# formula 생성
formula <-  Temp ~ Solar.R +  Wind + Ozone

# 분류모델 생성 : formula를 이용하여 분류모델 생성 
air_ctree <- ctree(formula, data=airquality)
air_ctree

plot(air_ctree)

#----------------<<실습2>>-------------------------------
# 학습데이터와 검정데이터 샘플링으로 분류분석 
# 4개변수(Sepal Length,Sepal Width,Petal Length,Petal Width) 
# 값에 따라서 꽃의 종류(Species)가 분류되는 분석 과정
#--------------------------------------------------------

#단계1 : 학습데이터와 검증데이터 샘플링
#set.seed(1234) # 메모리에 시드값 적용 - 동일값 생성 
idx <- sample(1:nrow(iris), nrow(iris) * 0.7) 
train <- iris[idx,] 
test <- iris[-idx,]  

# 단계2 : formula 생성 
#  -> 형식) 변수 <- 종속변수 ~ 독립변수
formula <- Species ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width 


#단계3 : 학습데이터 이용 분류모델 생성(ctree()함수 이용)
iris_ctree <- ctree(formula, data=train) # 학습데이터로 분류모델(tree) 생성
iris_ctree # 중요변수 확인 

#단계4 : 분류모델 플로팅 : plot() 이용
plot(iris_ctree, type="simple") 
plot(iris_ctree) # 의사결정트리 해석

#단계5 : 예측치 
pred <- predict(iris_ctree, test) # 45
pred # Y변수 값으로 예측 

#단계6 : 모델 평가 
table(pred, test$Species)


#-------------------<<실습3>>-------------------------
# K겹 교차검정 샘플링으로 분류분석 
# - iris 데이터 셋을 대상으로 K=3, R=2 교차검정
#-----------------------------------------------------

#단계1: K겹 교차검정을 위한 샘플링 
library(cvTools)
cross <- cvFolds(nrow(iris), K=3, R=2) 

#단계2: K겹 교차검정 데이터 보기
str(cross) # 구조 보기 

cross # 5겹 교차검정 데이터 보기
length(cross$which) # 150
dim(cross$subsets) # 150   2


#단계3: K겹 교차검정 수행  
R=1:2 # 2회 반복  
K=1:3 # 3겹  

for(r in R){ # 2회 
  cat('\n R=',r, '\n')  
  
  for(k in K){ # 3회 
    datas_idx <- cross$subsets[cross$which==k, r]  
    cat('K=',k,'검정데이터 \n')  
    test <- iris[datas_idx, ] # 검정데이터 생성
    print(test)  
    
    
    for(i in K[-k]){  # 6회(3*2) 반복
      formula <- Species ~ .
      datas_idx <- cross$subsets[cross$which==i, r]  
      cat('K=',i,'훈련데이터 \n') 
      train <- iris[datas_idx, ]   # 훈련데이터 생성 
      print(train)         
    }      
  }    
} 


library(rpart) # rpart() : 분류모델 생성 
install.packages("rpart.plot")
library(rpart.plot) # prp(), rpart.plot() : rpart 시각화
install.packages('rattle')
library('rattle') # fancyRpartPlot() : node 번호 시각화 


# 단계1. 실습데이터 생성 
data(iris)
set.seed(415)
idx = sample(1:nrow(iris), 0.7*nrow(iris))
train = iris[idx, ]
test = iris[-idx, ]
dim(train) # 105 5
dim(test) # 45  5

table(train$Species)

# 단계2. 분류모델 생성 
# rpart(y변수 ~ x변수, data)
model = rpart(Species~., data=train) # iris의 꽃의 종류(Species) 분류 
model

# 분류모델 시각화 - rpart.plot 패키지 제공 
prp(model) # 간단한 시각화   
rpart.plot(model) # rpart 모델 tree 출력
fancyRpartPlot(model) # node 번호 출력(rattle 패키지 제공)


# 단계3. 분류모델 평가  
pred <- predict(model, test, type="class") # 분류 예측 

# 1) 분류모델로 분류된 y변수 보기 
table(pred)

# 2) 분류모델 성능 평가 
table(pred, test$Species)


##################################################
# Decision Tree 응용실습 : 암 진단 분류 분석
##################################################
# "wdbc_data.csv" : 유방암 진단결과 데이터 셋 분류

# 1. 데이터셋 가져오기 
wdbc <- read.csv('C:/Rwork-II/data/wdbc_data.csv', stringsAsFactors = FALSE)
str(wdbc)

# 2. 데이터 탐색 및 전처리 
wdbc <- wdbc[-1] # id 칼럼 제외(이상치) 
head(wdbc)
head(wdbc[, c('diagnosis')], 10) # 진단결과 : B -> '양성', M -> '악성'

# 목표변수(y변수)를 factor형으로 변환 
wdbc$diagnosis <- factor(wdbc$diagnosis, levels = c("B", "M"))
wdbc$diagnosis[1:10]

# 3. 정규화 - scale() : 서로 다른 특징을 갖는 칼럼값을 균등하게 적용 
normalize <- function(x){ # 정규화를 위한 함수 정의 
  return ((x - min(x)) / (max(x) - min(x)))
}

# wdbc[2:31] : x변수에 해당한 칼럼 대상 정규화 수행 
wdbc_x <- as.data.frame(lapply(wdbc[2:31], normalize))
wdbc_x
summary(wdbc_x) # 0 ~ 1 사이 정규화 
class(wdbc_x) # [1] "data.frame"
nrow(wdbc_x) # [1] 569

wdbc_df <- data.frame(wdbc$diagnosis, wdbc_x)
dim(wdbc_df) # 569  31
head(wdbc_df)

# 4. 훈련데이터와 검정데이터 생성 : 7 : 3 비율 
idx = sample(nrow(wdbc_df), 0.7*nrow(wdbc_df))
wdbc_train = wdbc_df[idx, ] # 훈련 데이터 
wdbc_test = wdbc_df[-idx, ] # 검정 데이터 
dim(wdbc_train) # [1] 398  30
dim(wdbc_test) # [1] 171  30

# 5. rpart 분류모델 생성 

# 6. 분류모델 평가  
